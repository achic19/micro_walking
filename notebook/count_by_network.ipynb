{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import momepy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from geopandas import GeoDataFrame\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pandas import DataFrame\n",
    "layer_crs= 'epsg:2039'\n",
    "project_folder = os.path.dirname(os.getcwd())\n",
    "data_folder = 'elements_as_graph'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Start by merging files\n",
    "# 1. Create new folder for each attribute\n",
    "folder_names  = ['educational_institutes','synagogues','Leisure_amenities','Sport_facilities','Health_services','Playgrounds']\n",
    "for name in folder_names:\n",
    "    os.makedirs(project_folder + r'\\TelAvivLayers\\{}\\{}'.format(data_folder,name),exist_ok = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 2. uzip files\n",
    "# folder_to_zip = glob.glob(project_folder + r'\\TelAvivLayers\\{}\\*\\*'.format(data_folder))\n",
    "# for file_path in folder_to_zip:\n",
    "#     with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(os.path.dirname(file_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on educational_institutes\n",
      "in Kindergartens.shp has 662 educational_institutes \n",
      "in Schools.shp has 211 educational_institutes \n",
      "there is  873 educational_institutes\n",
      "run on Health_services\n",
      "in Family Health.shp has 15 Health_services \n",
      "in Medical Aids.shp has 63 Health_services \n",
      "in Pharmacies.shp has 122 Health_services \n",
      "there is  200 Health_services\n",
      "run on Leisure_amenities\n",
      "in Art Galeries.shp has 73 Leisure_amenities \n",
      "in Cinemas.shp has 6 Leisure_amenities \n",
      "in Museums.shp has 24 Leisure_amenities \n",
      "in Music Centers.shp has 13 Leisure_amenities \n",
      "in Theaters.shp has 13 Leisure_amenities \n",
      "there is  129 Leisure_amenities\n",
      "run on Playgrounds\n",
      "in Playgrounds.shp has 385 Playgrounds \n",
      "there is  385 Playgrounds\n",
      "run on Sport_facilities\n",
      "in Garden Sports Facilities.shp has 154 Sport_facilities \n",
      "in Gyms.shp has 39 Sport_facilities \n",
      "in Sport Lots.shp has 407 Sport_facilities \n",
      "in Sports Halls.shp has 102 Sport_facilities \n",
      "in Stadiums.shp has 6 Sport_facilities \n",
      "in Swimming Pools.shp has 17 Sport_facilities \n",
      "there is  725 Sport_facilities\n",
      "run on synagogues\n",
      "in Synagogues.shp has 481 synagogues \n",
      "there is  481 synagogues\n"
     ]
    }
   ],
   "source": [
    "# 3. merge all files of the same kind\n",
    "path_by_subgect = glob.glob(project_folder + r'\\TelAvivLayers\\{}\\*'.format(data_folder))\n",
    "for path in path_by_subgect:\n",
    "    data_list = []\n",
    "    name =(os.path.basename(path))\n",
    "    print('run on {}'.format(name))\n",
    "    files_path= glob.glob(r'{}\\*.shp'.format(path))\n",
    "    cols = ['geometry']\n",
    "    for file_path in files_path:\n",
    "        file =  gpd.read_file(file_path)[cols].reset_index()\n",
    "        # Make sure the file is in the correct CRS and if not, transform it to the right one\n",
    "        if file .crs.srs !=layer_crs:\n",
    "            print('different crs')\n",
    "            file.to_crs(layer_crs)\n",
    "        file_name =  file_path.split('\\\\')[-1]\n",
    "        print('in {} has {} {} '.format(file_name ,len(file),name))\n",
    "        file['name'] = file_name\n",
    "        data_list.append(file)\n",
    "    # Combine all and leave only one among those  with the same geometry\n",
    "    one_file = pd.concat(data_list)\n",
    "    print('there is  {} {}'.format(len(one_file),name))\n",
    "    one_file.to_file('output/streets_elements/elements/{}/{}.shp'.format(data_folder,name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\anaconda3\\envs\\momepy_env\\lib\\site-packages\\libpysal\\weights\\weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 29 disconnected components.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# The network to work with\n",
    "res_path = 'output/streets_elements'\n",
    "graph_path = f'{res_path}/elements/graph/'\n",
    "clean_network = gpd.read_file(r'{}/streets_elements.shp'.format(res_path))\n",
    "network_for_graph = gpd.read_file(f'{graph_path}/split_network.shp')\n",
    "col_to_leave = ['oidrechov','length','geometry']\n",
    "\n",
    "# The new network will contain more information for each object and will also be transformed into a graph\n",
    "clean_network_temp =clean_network[col_to_leave]\n",
    "G = momepy.gdf_to_nx(network_for_graph, approach=\"primal\", length='length')\n",
    "nodes, edges, W = momepy.nx_to_gdf(G, spatial_weights=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Assign graph elements to a SHP file\n",
    "nodes.to_file('{}/elements/graph/nodes.shp'.format(res_path))\n",
    "edges.to_file('{}/elements/graph/edges.shp'.format(res_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# For a given element, this function calculates the closet node between two closet edge nodes\n",
    "def find_closet_pnt(row):\n",
    "    start_pnt = nodes.loc[row['node_start']].geometry\n",
    "    end_pnt = nodes.loc[row['node_end']].geometry\n",
    "    if row.geometry.distance(start_pnt) <row.geometry.distance(end_pnt):\n",
    "        return row['node_start']\n",
    "    else:\n",
    "         return row['node_end']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# \"ego_graph\" is used to calculate all edges whose paths to them from the given node (stored in row variable) are shorter than the radius value.\n",
    "def find_close_edges(row, radius):\n",
    "    flag =True\n",
    "    node_id = row['nodeID']\n",
    "    node_geometry = nodes[nodes['nodeID']==node_id]['geometry'].to_list()[0]\n",
    "    G_temp = nx.generators.ego_graph(G, (node_geometry.x,node_geometry.y), radius=radius, distance='length')\n",
    "    try:\n",
    "        nodes_0, edges_0, W = momepy.nx_to_gdf(G_temp, spatial_weights=True)\n",
    "    except ValueError:\n",
    "        # In the case of a single edge\n",
    "        temp_row_id = row['oidrechov']\n",
    "        print('{}:only one polyline is found'.format(node_id))\n",
    "        temp_count = clean_network_temp[clean_network_temp['oidrechov']==temp_row_id][count_field]\n",
    "        clean_network_temp[clean_network_temp['oidrechov']==temp_row_id][count_field]= temp_count +1\n",
    "        flag = False\n",
    "    if flag:\n",
    "        # Add one to all the founded edges (which denote that these streets are close to the given object)\n",
    "        clean_network_temp.loc[clean_network_temp['oidrechov'].isin(edges_0['oidrechov']),count_field] = clean_network_temp.loc[clean_network_temp['oidrechov'].isin(edges_0['oidrechov']),count_field] +1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "educational_institutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_13936\\2495793.py:13: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  sjoin.to_file('{}/sjoin.shp'.format(path2))\n",
      "C:\\Users\\Achituv\\anaconda3\\envs\\momepy_env\\lib\\site-packages\\geopandas\\geodataframe.py:1472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "6540:only one polyline is found\n",
      "6540:only one polyline is found\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\anaconda3\\envs\\momepy_env\\lib\\site-packages\\geopandas\\geodataframe.py:1472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6540:only one polyline is found\n",
      "6540:only one polyline is found\n",
      "600\n",
      "6540:only one polyline is found\n",
      "6540:only one polyline is found\n",
      "synagogues\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_13936\\2495793.py:13: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  sjoin.to_file('{}/sjoin.shp'.format(path2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "600\n",
      "Leisure_amenities\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_13936\\2495793.py:13: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  sjoin.to_file('{}/sjoin.shp'.format(path2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "600\n",
      "Sport_facilities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_13936\\2495793.py:13: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  sjoin.to_file('{}/sjoin.shp'.format(path2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "500\n",
      "600\n",
      "Health_services\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_13936\\2495793.py:13: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  sjoin.to_file('{}/sjoin.shp'.format(path2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "600\n",
      "Playgrounds\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_13936\\2495793.py:13: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  sjoin.to_file('{}/sjoin.shp'.format(path2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_13936\\2495793.py:24: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  clean_network.to_file(r'{}/streets_elements_as_graph.shp'.format(res_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "# The code should be applied to all objects in the \"files_count_as_network\" list.\n",
    "files_count_as_network = ['educational_institutes','synagogues','Leisure_amenities','Sport_facilities','Health_services','Playgrounds']\n",
    "for name in files_count_as_network:\n",
    "    print(name)\n",
    "    path = '{}/elements/elements_as_graph/{}'.format(res_path,name)\n",
    "    path2 = '{}/detailed_folder/elements_as_graph/{}'.format(res_path,name)\n",
    "    object_file = gpd.read_file('{}.shp'.format(path))\n",
    "    # Find the closet node for each object\n",
    "    sjoin= object_file.sjoin_nearest(edges,distance_col='dis')\n",
    "    sjoin['nodeID'] = sjoin.apply(find_closet_pnt,axis=1)\n",
    "    os.makedirs(path2,exist_ok = True)\n",
    "    sjoin.drop_duplicates(subset=['index', 'nodeID'],inplace=True)\n",
    "    sjoin.to_file('{}/sjoin.shp'.format(path2))\n",
    "\n",
    "    radiuses = [400,500,600]\n",
    "    for val in radiuses:\n",
    "    # Use one of the radiuses to apply the closet edges in the graph\n",
    "        print(val)\n",
    "        count_field = 'count{}'.format(val)\n",
    "        clean_network_temp[count_field] = 0\n",
    "        sjoin.apply(lambda x:find_close_edges(x,val),axis=1)\n",
    "    clean_network_temp.to_file('{}/{}.shp'.format(path2,name))\n",
    "    clean_network[name] = clean_network_temp['count400']\n",
    "clean_network.to_file(r'{}/streets_elements_as_graph.shp'.format(res_path))\n",
    "print('Finish')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}