{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import momepy\n",
    "import geopandas as gpd\n",
    "import networkx\n",
    "from osmnx import io\n",
    "from geopandas import GeoDataFrame, GeoSeries\n",
    "from centerline.geometry import Centerline\n",
    "path ='output'\n",
    "project_crs = 'epsg:3857'\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.cluster import DBSCAN\n",
    "from shapely.geometry import Polygon,Point,LineString,MultiPolygon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run only when download for first time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Create graph from OSM server and project it\n",
    "graph = ox.graph_from_place('Torino', network_type='all')\n",
    "graph  = ox.bearing.add_edge_bearings(graph, precision=1)\n",
    "graph_pro = ox.projection.project_graph(graph, to_crs=project_crs)\n",
    "io.save_graph_geopackage(graph_pro, filepath='.', encoding='utf-8', directed=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### End"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# delete segments without names\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m my_gdf \u001B[38;5;241m=\u001B[39m \u001B[43mgpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_file(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/edges.shp\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m not_null\u001B[38;5;241m=\u001B[39m my_gdf\u001B[38;5;241m.\u001B[39mdropna(subset\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m not_null\u001B[38;5;241m.\u001B[39mto_file(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/not_null.shp\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'gpd' is not defined"
     ]
    }
   ],
   "source": [
    "# delete segments without names\n",
    "my_gdf = gpd.read_file(f'{path}/edges.shp')\n",
    "not_null= my_gdf.dropna(subset='name')\n",
    "not_null.to_file(f'{path}/not_null.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# delete segments present any kind of roundabout or tunnel\n",
    "not_roundaout = not_null[~((not_null['junction']=='roundabout')|(not_null['junction']=='circular')|(not_null['tunnel']=='building_passage')|(not_null['tunnel']=='yes')| (not_null['highway']=='cycleway')| (not_null['highway']=='path'))]\n",
    "not_roundaout.to_file(f'{path}/not_roundabout_tunnel.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Project dataframe and calculate angle (0 to 180)\n",
    "df_pro = not_roundaout.to_crs(project_crs)\n",
    "df_pro['angle'] = df_pro['bearing'].apply(lambda x:x if x<180 else x-180)\n",
    "df_pro.to_file(f'{path}/pro.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# only the first value will be saed highway with more than 1 value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def length_of_parallel(my_s_join: GeoDataFrame, the_buffer:GeoSeries, geo_field:str)-> int:\n",
    "    my_s_join['geometry'] =my_s_join[geo_field]\n",
    "    new_data_0 = my_s_join.sjoin(GeoDataFrame(geometry=the_buffer, crs= project_crs), how='inner').reset_index()\n",
    "    if len(new_data_0)==0:\n",
    "        return 0\n",
    "    return len(new_data_0[new_data_0['index']!= new_data_0['index_right']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def check_parallelism(to_translate: GeoDataFrame, is_test:bool=False)->bool:\n",
    "    my_buffer = to_translate['geometry'].buffer(cap_style=2, distance=30, join_style=3)\n",
    "    to_translate['geometry_right'] = to_translate['geometry'].apply(lambda x:x.parallel_offset(35, 'right'))\n",
    "    to_translate['geometry_left'] = to_translate['geometry'].apply(lambda x:x.parallel_offset(35, 'left'))\n",
    "    # Currently is it not working\n",
    "    if is_test:\n",
    "        # to_translate.drop(columns= ['geometry', new_geometry[0]]).rename(columns = {new_geometry[1]: 'geometry'}).to_file(f'{path}/test_data/res_translate_{new_geometry[1]}.shp')\n",
    "        # to_translate.drop(columns= ['geometry', new_geometry[1]]).rename(columns = {new_geometry[0]: 'geometry'}).to_file(f'{path}/test_data/res_translate_{new_geometry[0]}.shp')\n",
    "        my_buffer.to_file(f'{path}/test_data/buffers_test.shp')\n",
    "    if length_of_parallel(to_translate, my_buffer, 'geometry_right') >0 or length_of_parallel(to_translate, my_buffer, 'geometry_left') >0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def simplify(my_polygon:Polygon,x:(int,float))-> Polygon:\n",
    "    simplify_poly = my_polygon.simplify(x, preserve_topology=False)\n",
    "    if simplify_poly.area<50:\n",
    "        simplify_poly= simplify(my_polygon,x/2)\n",
    "    return simplify_poly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def create_center_line():\n",
    "    \"\"\"\n",
    "    This method calculate new line between the farthest points of the simplified polygon\n",
    "    :param one_poly:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    one_poly = simplify(polygon, 100)\n",
    "    pnt_list = one_poly.exterior.coords[:-1]\n",
    "    list_shp = [Point(item) for item in pnt_list]\n",
    "    dis = 0\n",
    "    max_dis = (-1, -1)\n",
    "    # The new line will be determined by the farthest points\n",
    "    for i, point in enumerate(list_shp):\n",
    "        j = i\n",
    "        for point2 in list_shp[i + 1:]:\n",
    "            j += 1\n",
    "            if point.distance(point2) > dis:\n",
    "                max_dis = (i, j)\n",
    "                dis = point.distance(point2)\n",
    "    if is_test:\n",
    "        dic_sim = {'index':[0],'geometry':one_poly}\n",
    "        GeoDataFrame(dic_sim,crs='epsg:3857').to_file(f'{path}/test_data/simplify_poly_{unit[0]}_{id_pol + 2}.shp')\n",
    "    max_dist['name'].extend([id_pol + 2, id_pol + 2])\n",
    "    max_dist['geometry'].extend([list_shp[max_dis[0]], list_shp[max_dis[1]]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "def update_df_with_center_line(new_line):\n",
    "    \"\"\"\n",
    "    update our dictionary with new lines\n",
    "    :param new_line:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dic_final['name'].append(name)\n",
    "    # dic_final['geometry'].append(LineString(coordinates=(pnt_list[max_dis[0]], pnt_list[max_dis[1]])))\n",
    "    dic_final['geometry'].append(new_line)\n",
    "    dic_final['highway'].append(data.iloc[0]['highway'])\n",
    "    dic_final['bearing'].append(data['angle'].mean())\n",
    "    dic_final['group'].append(unit[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_pro = gpd.read_file((f'{path}/pro.shp'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "def update_list(line):\n",
    "    \"\"\"\n",
    "    add the first start/end point into the list\n",
    "    :param line:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    list_pnts_of_line_group.extend([Point(line.coords[0]), Point(line.coords[-1])])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_33096\\1885651142.py:33: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for id_pol, polygon in enumerate(one_buffer):\n",
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_33096\\1885651142.py:33: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for id_pol, polygon in enumerate(one_buffer):\n",
      "C:\\Users\\Achituv\\AppData\\Local\\Temp\\ipykernel_33096\\1885651142.py:33: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for id_pol, polygon in enumerate(one_buffer):\n"
     ]
    }
   ],
   "source": [
    "# Main point to start\n",
    "is_test = False\n",
    "my_groupby = df_pro.groupby('name')\n",
    "dic_final = {'name': [], 'geometry': [], 'highway': [], 'bearing': [],'group':[]}\n",
    "new_lines = {'name':[],'geometry':[]}\n",
    "for_time = len(my_groupby)\n",
    "for i, street in enumerate(my_groupby):\n",
    "    # Calculate time to run ToDo\n",
    "    # print(round(i / for_time * 100, 2))\n",
    "    res = street[1]\n",
    "    name = street[0]\n",
    "    # ToDo for test\n",
    "    name = 'Via Verolengo'\n",
    "    res = df_pro[df_pro['name']==name]\n",
    "    ####\n",
    "    # groupby angle\n",
    "    res =  res.dropna(subset= ['angle'],axis=0)\n",
    "    if len(res)==0:\n",
    "        continue\n",
    "    res['group'] = DBSCAN(eps=5, min_samples=2).fit(res['angle'].to_numpy().reshape(-1, 1)).labels_\n",
    "    cur_group = res[res['group'] > -1].groupby('group')\n",
    "    is_parallel=False\n",
    "    for group in cur_group:\n",
    "        data = group[1]\n",
    "        if check_parallelism(data, is_test=False):\n",
    "            # if among of lines with same angles some are parallel,find the center line for each group\n",
    "            is_parallel = True\n",
    "            for unit in cur_group:\n",
    "                data = unit[1]\n",
    "                # new points DataFrame of start/end line of each group\n",
    "                list_pnts_of_line_group = []\n",
    "                data['geometry'].apply(update_list)\n",
    "                df_pnts = GeoDataFrame(geometry=list_pnts_of_line_group,crs='epsg:3857').drop_duplicates()\n",
    "\n",
    "                # unify lines to one polygon\n",
    "                buffers = data.buffer(cap_style=3, distance=30, join_style=3)\n",
    "                one_buffer = buffers.unary_union\n",
    "\n",
    "                max_dist = {'name':[], 'geometry':[]}\n",
    "                # simplify polygon with simplify function. If one_buffer is multipolygon object simplify each one them separately\n",
    "                if isinstance(one_buffer, MultiPolygon):\n",
    "                    for id_pol, polygon in enumerate(one_buffer):\n",
    "                       create_center_line()\n",
    "                else:\n",
    "                    id_pol =-1\n",
    "                    create_center_line()\n",
    "                max_df = GeoDataFrame(max_dist, crs='epsg:3857')\n",
    "                # find for each points the closet point from the oribinal data. the closet points will create the new line\n",
    "                s_join = max_df.sjoin_nearest(df_pnts).groupby('name')\n",
    "                for geo in s_join:\n",
    "                    same_name =geo[1]\n",
    "                    if same_name.iloc[0]['index_right'] ==same_name.iloc[1]['index_right']:\n",
    "                        continue\n",
    "                    in_0 = same_name.iloc[0]['index_right']\n",
    "                    in_1 = same_name.iloc[1]['index_right']\n",
    "                    new_lines['geometry'].append(LineString([df_pnts.loc[in_0]['geometry'],df_pnts.loc[in_1]['geometry']]))\n",
    "                    new_lines['name'].append(geo[0])\n",
    "\n",
    "                if is_test:\n",
    "                    buffers.to_file(f'{path}/test_data/buffers_{unit[0]}.shp')\n",
    "                    # dic_one = {'index':[0],'geometry':one_buffer.geoms}\n",
    "                    # GeoDataFrame(dic_one,crs='epsg:3857').to_file(f'{path}/test_data/one_buffer_{unit[0]}.shp')\n",
    "        # if one group is found as parallel all the groups are calculated as parallel so we don't need to check_parallelism\n",
    "        GeoDataFrame(new_lines, crs='epsg:3857').to_file(f'{path}/test_data/one_line_manty.shp')\n",
    "        if is_parallel:\n",
    "            break\n",
    "\n",
    "    # ToDo for test\n",
    "    break\n",
    "\n",
    "\n",
    "# ToDo for test\n",
    "# GeoDataFrame(dic_final, crs='epsg:3857').to_file(f'{path}/one_line.shp')\n",
    "# # create network\n",
    "# new_network = df_pro[~df_pro['name'].isin(dic_final['name'])][list(dic_final.keys())]\n",
    "# new_network['is_simplify'] = 0\n",
    "# simplify = GeoDataFrame(dic_final, crs='epsg:3857')\n",
    "# simplify['is_simplify'] = 1\n",
    "# new_network.append(simplify).to_file(f'{path}/new_network.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "new_lines = {'name':[],'geometry':[]}\n",
    "s_join = max_df.sjoin_nearest(df_pnts).groupby('name')\n",
    "for geo in s_join:\n",
    "    same_name =geo[1]\n",
    "    if same_name.iloc[0]['index_right'] ==same_name.iloc[1]['index_right']:\n",
    "        continue\n",
    "    in_0 = same_name.iloc[0]['index_right']\n",
    "    in_1 = same_name.iloc[1]['index_right']\n",
    "    new_lines['geometry'].append(LineString([df_pnts.loc[in_0]['geometry'],df_pnts.loc[in_1]['geometry']]))\n",
    "    new_lines['name'].append(geo[0])\n",
    "GeoDataFrame(new_lines, crs='epsg:3857').to_file(f'{path}/test_data/one_line_updated.shp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "<shapely.geometry.linestring.LineString at 0x1946b3f83a0>",
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"178.1271103080362\" viewBox=\"851575.7858331379 5636422.724617999 1466.3248230167665 178.1271103080362\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,11273023.576346306)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"9.775498820111777\" points=\"851630.0941599163,5636477.032944777 852987.8023293763,5636546.543401529\" opacity=\"0.8\" /></g></svg>"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LineString([df_pnts.loc[18]['geometry'],df_pnts.loc[40]['geometry']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "shapely.geometry.point.Point"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pnts.loc[18]['geometry'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}